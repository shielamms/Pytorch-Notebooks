{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "trainset = datasets.FashionMNIST('./FashionMNISTdata2', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = datasets.FashionMNIST('./FashionMNISTdata2', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Untrained Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "\n",
    "images, labels = next(iter(testloader))\n",
    "ps = torch.exp(model(images))\n",
    "\n",
    "print(ps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5],\n",
      "        [5],\n",
      "        [5],\n",
      "        [5],\n",
      "        [5],\n",
      "        [5],\n",
      "        [5],\n",
      "        [5],\n",
      "        [5],\n",
      "        [5]])\n",
      "torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "# Check which classes have the highest probability\n",
    "top_p, top_class = ps.topk(1, dim=1)\n",
    "\n",
    "print(top_class[:10, :])\n",
    "print(top_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equals = top_class == labels.view(*top_class.shape)\n",
    "equals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 14.0625%\n"
     ]
    }
   ],
   "source": [
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "print(f'Accuracy: {accuracy.item()*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 30\n",
    "steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30.. Training Loss: 0.393.. Test Loss: 0.465.. Test Accuracy: 0.824..\n",
      "Epoch: 2/30.. Training Loss: 0.353.. Test Loss: 0.382.. Test Accuracy: 0.866..\n",
      "Epoch: 3/30.. Training Loss: 0.337.. Test Loss: 0.395.. Test Accuracy: 0.860..\n",
      "Epoch: 4/30.. Training Loss: 0.318.. Test Loss: 0.389.. Test Accuracy: 0.863..\n",
      "Epoch: 5/30.. Training Loss: 0.301.. Test Loss: 0.384.. Test Accuracy: 0.867..\n",
      "Epoch: 6/30.. Training Loss: 0.296.. Test Loss: 0.357.. Test Accuracy: 0.874..\n",
      "Epoch: 7/30.. Training Loss: 0.283.. Test Loss: 0.381.. Test Accuracy: 0.868..\n",
      "Epoch: 8/30.. Training Loss: 0.277.. Test Loss: 0.347.. Test Accuracy: 0.879..\n",
      "Epoch: 9/30.. Training Loss: 0.268.. Test Loss: 0.373.. Test Accuracy: 0.873..\n",
      "Epoch: 10/30.. Training Loss: 0.264.. Test Loss: 0.375.. Test Accuracy: 0.872..\n",
      "Epoch: 11/30.. Training Loss: 0.259.. Test Loss: 0.387.. Test Accuracy: 0.875..\n",
      "Epoch: 12/30.. Training Loss: 0.248.. Test Loss: 0.381.. Test Accuracy: 0.874..\n",
      "Epoch: 13/30.. Training Loss: 0.247.. Test Loss: 0.361.. Test Accuracy: 0.880..\n",
      "Epoch: 14/30.. Training Loss: 0.240.. Test Loss: 0.363.. Test Accuracy: 0.877..\n",
      "Epoch: 15/30.. Training Loss: 0.232.. Test Loss: 0.405.. Test Accuracy: 0.877..\n",
      "Epoch: 16/30.. Training Loss: 0.232.. Test Loss: 0.387.. Test Accuracy: 0.878..\n",
      "Epoch: 17/30.. Training Loss: 0.232.. Test Loss: 0.389.. Test Accuracy: 0.876..\n",
      "Epoch: 18/30.. Training Loss: 0.221.. Test Loss: 0.380.. Test Accuracy: 0.879..\n",
      "Epoch: 19/30.. Training Loss: 0.220.. Test Loss: 0.396.. Test Accuracy: 0.876..\n",
      "Epoch: 20/30.. Training Loss: 0.214.. Test Loss: 0.396.. Test Accuracy: 0.874..\n",
      "Epoch: 21/30.. Training Loss: 0.211.. Test Loss: 0.384.. Test Accuracy: 0.884..\n",
      "Epoch: 22/30.. Training Loss: 0.205.. Test Loss: 0.403.. Test Accuracy: 0.875..\n",
      "Epoch: 23/30.. Training Loss: 0.202.. Test Loss: 0.446.. Test Accuracy: 0.875..\n",
      "Epoch: 24/30.. Training Loss: 0.196.. Test Loss: 0.450.. Test Accuracy: 0.871..\n",
      "Epoch: 25/30.. Training Loss: 0.202.. Test Loss: 0.395.. Test Accuracy: 0.883..\n",
      "Epoch: 26/30.. Training Loss: 0.193.. Test Loss: 0.416.. Test Accuracy: 0.882..\n",
      "Epoch: 27/30.. Training Loss: 0.192.. Test Loss: 0.445.. Test Accuracy: 0.874..\n",
      "Epoch: 28/30.. Training Loss: 0.190.. Test Loss: 0.450.. Test Accuracy: 0.876..\n",
      "Epoch: 29/30.. Training Loss: 0.188.. Test Loss: 0.435.. Test Accuracy: 0.879..\n",
      "Epoch: 30/30.. Training Loss: 0.183.. Test Loss: 0.443.. Test Accuracy: 0.878..\n"
     ]
    }
   ],
   "source": [
    "train_losses, test_losses = [], []\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    \n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        log_ps = model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        # Validation Pass goes here\n",
    "        with torch.no_grad():\n",
    "            for test_images, test_labels in testloader:\n",
    "                test_log_ps = model(test_images)\n",
    "                test_loss += criterion(test_log_ps, test_labels)\n",
    "                \n",
    "                test_ps = torch.exp(test_log_ps)\n",
    "                top_test_p, top_test_class = test_ps.topk(1, dim=1)\n",
    "                \n",
    "                test_label_comparison = top_test_class == test_labels.view(*top_test_class.shape)\n",
    "                accuracy += torch.mean(test_label_comparison.type(torch.FloatTensor))\n",
    "                \n",
    "        train_losses.append(running_loss / len(trainloader))\n",
    "        test_losses.append(test_loss / len(testloader))\n",
    "        \n",
    "        print('Epoch: {}/{}..'.format(e+1, epochs),\n",
    "              'Training Loss: {:.3f}..'.format(running_loss/len(trainloader)),\n",
    "              'Test Loss: {:.3f}..'.format(test_loss/len(testloader)),\n",
    "              'Test Accuracy: {:.3f}..'.format(accuracy/len(testloader))\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
